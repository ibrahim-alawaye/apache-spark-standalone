services:
  spark-worker-2:
    build:
      context: .
      dockerfile: Dockerfile.spark
    container_name: spark-engine-spark-worker-2
    command: >
      /opt/spark/bin/spark-class org.apache.spark.deploy.worker.Worker spark://spark-master:7077
    environment:
      - SPARK_MODE=worker
      - SPARK_NO_DAEMONIZE=true
      - SPARK_LOCAL_IP=172.20.0.10
      - SPARK_WORKER_WEBUI_PORT=8081
      - SPARK_WORKER_PORT=0
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - SPARK_METRICS_ON=true
      - SPARK_WORKER_MEMORY=${SPARK_WORKER_MEMORY}
      - SPARK_WORKER_CORES=${SPARK_WORKER_CORES}
      - PYSPARK_PYTHON=/usr/bin/python3
      - PYSPARK_DRIVER_PYTHON=/usr/bin/python3
      - SPARK_EXECUTOR_MEMORY=${SPARK_EXECUTOR_MEMORY}
      - SPARK_EXECUTOR_CORES=${SPARK_EXECUTOR_CORES}
      - SPARK_EXECUTOR_INSTANCES=${SPARK_EXECUTOR_INSTANCES}
      - SPARK_METRICS_CONF=/opt/spark/conf/metrics.properties
      - SPARK_JAVA_OPTS=-javaagent:/opt/spark/jars/jmx_prometheus_javaagent.jar=9091:/opt/spark/conf/prometheus.yml
    volumes:
      - ./config/${SPARK_ENV}/spark-defaults.conf:/opt/spark/conf/spark-defaults.conf
      - ./config/${SPARK_ENV}/spark-conf:/opt/spark/conf
      - /tmp/spark-events:/tmp/spark-events
      - /tmp/spark-temp:/tmp/spark-temp
      - "./spark-jobs:/root/spark-jobs"
      - ./monitoring/jmx/jmx_prometheus_javaagent.jar:/opt/spark/jars/jmx_prometheus_javaagent.jar
    expose:
      - "8081"
      - "2225:22"
    depends_on:
      spark-master:
        condition: service_healthy
      redis:
        condition: service_healthy
    networks:
      spark_network:
        ipv4_address: 172.20.0.10

networks:
  spark_network:
    external: true
    name: spark-engine_spark_network