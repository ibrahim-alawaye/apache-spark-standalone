

services:
  spark-master:
    platform: linux/amd64
    build:
      context: .
      dockerfile: Dockerfile.spark
    container_name: spark-master
    hostname: spark-master
    command: >
      /opt/spark/bin/spark-class org.apache.spark.deploy.master.Master
    environment:
      - SPARK_MODE=master
      - SPARK_NO_DAEMONIZE=true
      - SPARK_LOCAL_IP=172.20.0.2
      - SPARK_MASTER_HOST=172.20.0.2
      - SPARK_MASTER_PORT=7077
      - SPARK_MASTER_WEBUI_PORT=8080
      - SPARK_DRIVER_HOST=172.20.0.2
      - SPARK_DRIVER_BIND_ADDRESS=172.20.0.2
      - SPARK_METRICS_ON=true
      - PYSPARK_PYTHON=/usr/bin/python3
      - PYSPARK_DRIVER_PYTHON=/usr/bin/python3
      - SPARK_CONF_DIR=/opt/spark/conf
      - SPARK_METRICS_CONF=/opt/spark/conf/metrics.properties
      - SPARK_JAVA_OPTS=-javaagent:/opt/spark/jars/jmx_prometheus_javaagent.jar=9091:/opt/spark/conf/prometheus.yml
    ports:
      - "8080:8080"
      - "4040-4060:4040-4060" 
      - "7077:7077"
      - "9091:9091"
      - "2228:22" 
    volumes:
      - ./config/${SPARK_ENV}/spark-defaults.conf:/opt/spark/conf/spark-defaults.conf
      - ./config/${SPARK_ENV}/spark-conf:/opt/spark/conf
      - /tmp/spark-events:/tmp/spark-events
      - "./spark-jobs:/root/spark-jobs"
      - ./monitoring/jmx/jmx_prometheus_javaagent.jar:/opt/spark/jars/jmx_prometheus_javaagent.jar
    depends_on:
      redis:
        condition: service_healthy
    networks:
      spark_network:
        ipv4_address: 172.20.0.2
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://spark-master:8080 || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s

  spark-worker:
    platform: linux/amd64
    build:
      context: .
      dockerfile: Dockerfile.spark
    command: >
      /opt/spark/bin/spark-class org.apache.spark.deploy.worker.Worker spark://spark-master:7077
    environment:
      - SPARK_MODE=worker
      - SPARK_NO_DAEMONIZE=true
      - SPARK_LOCAL_IP=172.20.0.3
      - SPARK_WORKER_WEBUI_PORT=8081
      - SPARK_WORKER_PORT=0
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - SPARK_METRICS_ON=true
      - PYSPARK_PYTHON=/usr/bin/python3
      - PYSPARK_DRIVER_PYTHON=/usr/bin/python3
      - SPARK_WORKER_MEMORY=${SPARK_WORKER_MEMORY}
      - SPARK_WORKER_CORES=${SPARK_WORKER_CORES}
      - SPARK_EXECUTOR_MEMORY=${SPARK_EXECUTOR_MEMORY}
      - SPARK_EXECUTOR_CORES=${SPARK_EXECUTOR_CORES}
      - SPARK_METRICS_CONF=/opt/spark/conf/metrics.properties
      - SPARK_JAVA_OPTS=-javaagent:/opt/spark/jars/jmx_prometheus_javaagent.jar=9091:/opt/spark/conf/prometheus.yml
    ports:
      - "9092:9091"
      - "8081"
    volumes:
      - ./config/${SPARK_ENV}/spark-defaults.conf:/opt/spark/conf/spark-defaults.conf
      - ./config/${SPARK_ENV}/spark-conf:/opt/spark/conf
      - /tmp/spark-events:/tmp/spark-events
      - /tmp/spark-temp:/tmp/spark-temp
      - "./spark-jobs:/root/spark-jobs"
      - ./monitoring/jmx/jmx_prometheus_javaagent.jar:/opt/spark/jars/jmx_prometheus_javaagent.jar
    expose:
      - "8081"
      - "2223:22"
    depends_on:
      spark-master:
        condition: service_healthy
      redis:
        condition: service_healthy
    networks:
      spark_network:
        ipv4_address: 172.20.0.3
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:8081 || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 3

  redis:
    image: redis:alpine
    container_name: redis
    ports:
      - "6379:6379"
    volumes:
      - ./config/${SPARK_ENV}/redis.conf:/usr/local/etc/redis/redis.conf:ro
      - redis_data:/data
    command: redis-server /usr/local/etc/redis/redis.conf
    networks:
      spark_network:
        ipv4_address: 172.20.0.4
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 5s
      timeout: 3s
      retries: 3

  minio:
    image: minio/minio
    container_name: minio
    ports:
      - "9000:9000"
      - "9001:9001"
    environment:
      MINIO_ROOT_USER: ${MINIO_ACCESS_KEY:-minio}
      MINIO_ROOT_PASSWORD: ${MINIO_SECRET_KEY:-123456789}
    volumes:
      - minio_data:/data
    command: server /data --console-address ":9001"
    networks:
      spark_network:
        ipv4_address: 172.20.0.5
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:9000/minio/health/live || exit 1"]
      interval: 30s
      timeout: 20s
      retries: 3

  prometheus:
    image: prom/prometheus
    container_name: prometheus
    ports:
      - "9090:9090"
    volumes:
      - ./monitoring/prometheus:/etc/prometheus
    networks:
      spark_network:
        ipv4_address: 172.20.0.6
    depends_on:
      - spark-master
      - spark-worker

  grafana:
    image: grafana/grafana
    container_name: grafana
    user: root
    ports:
      - "3000:3000"
    volumes:
      - ./monitoring/grafana:/var/lib/grafana
    environment:
      - GF_PATHS_DATA=/var/lib/grafana
      - GF_PATHS_LOGS=/var/log/grafana
      - GF_USERS_ALLOW_SIGN_UP=false
    networks:
      spark_network:
        ipv4_address: 172.20.0.7
    depends_on:
      - prometheus

volumes:
  minio_data:
  redis_data:

networks:
  spark_network:
    name: spark-engine_spark_network
    driver: bridge
    ipam:
      config:
        - subnet: 172.20.0.0/16
